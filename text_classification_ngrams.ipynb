{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e10714",
   "metadata": {},
   "source": [
    "## Text Classification with N-grams and Preprocessing\n",
    "This notebook performs text classification on a news headlines dataset using n-grams and spaCy preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23015837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Imports and Initial Setup\n",
    "# -----------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Text Preprocessing Function\n",
    "# -----------------------------------\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Load and Prepare Dataset\n",
    "# -----------------------------------\n",
    "df = pd.read_json('News_Category_Dataset.json', lines=True)[['headline', 'category']]\n",
    "\n",
    "# Select relevant categories\n",
    "selected_categories = ['COMEDY', 'SPORTS', 'CRIME', 'EDUCATION']\n",
    "df_new = df[df['category'].isin(selected_categories)]\n",
    "\n",
    "# Balance the dataset (equal samples for each category)\n",
    "min_samples = df_new['category'].value_counts().min()\n",
    "df_balanced = pd.concat([\n",
    "    df_new[df_new.category == cat].sample(min_samples, random_state=2022)\n",
    "    for cat in selected_categories\n",
    "])\n",
    "\n",
    "# Encode labels\n",
    "category_map = {'COMEDY': 0, 'SPORTS': 1, 'CRIME': 2, 'EDUCATION': 3}\n",
    "df_balanced['category_num'] = df_balanced['category'].map(category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Original Text Classification (1-gram)\n",
    "# -----------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced['headline'], df_balanced['category_num'], \n",
    "    test_size=0.2, stratify=df_balanced['category_num'], random_state=2023\n",
    ")\n",
    "\n",
    "pipeline_bow = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 1))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_bow.fit(X_train, y_train)\n",
    "y_pred = pipeline_bow.predict(X_test)\n",
    "print(\"=== Classification Report: 1-gram ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# N-gram Model (1 to 2 grams)\n",
    "# -----------------------------------\n",
    "pipeline_bigrams = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_bigrams.fit(X_train, y_train)\n",
    "y_pred = pipeline_bigrams.predict(X_test)\n",
    "print(\"=== Classification Report: 1-2 grams ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf29a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# N-gram Model (1 to 3 grams)\n",
    "# -----------------------------------\n",
    "pipeline_trigrams = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_trigrams.fit(X_train, y_train)\n",
    "y_pred = pipeline_trigrams.predict(X_test)\n",
    "print(\"=== Classification Report: 1-3 grams ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Preprocess Headlines\n",
    "# -----------------------------------\n",
    "df_balanced['preprocessed_txt'] = df_balanced['headline'].apply(preprocess)\n",
    "\n",
    "# Train/Test Split on Preprocessed Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced['preprocessed_txt'], df_balanced['category_num'],\n",
    "    test_size=0.2, stratify=df_balanced['category_num'], random_state=2023\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Classification on Preprocessed Text (1-2 grams)\n",
    "# -----------------------------------\n",
    "pipeline_preprocessed = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_preprocessed.fit(X_train, y_train)\n",
    "y_pred = pipeline_preprocessed.predict(X_test)\n",
    "print(\"=== Classification Report: Preprocessed Text (1-2 grams) ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
